{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('FluPrediction').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flu = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \";\").load(\"Data/FluView.csv\")\n",
    "\n",
    "Area = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \"\\t\").load(\"Data/Area.csv\")\n",
    "Income = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"Data/Income.csv\")\n",
    "Health = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \";\").load(\"Data/HealthCare.csv\")\n",
    "Virus = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"Data/typeVirus.csv\")\n",
    "Population = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \"\\t\").load(\"Data/population.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+-----------+----+-------+\n",
      "|STATENAME|ACTIVITYESTIMATE|    WEEKEND|WEEK| SEASON|\n",
      "+---------+----------------+-----------+----+-------+\n",
      "|  Alabama|     No Activity|Oct-04-2003|  40|2003-04|\n",
      "|  Alabama|     No Activity|Oct-11-2003|  41|2003-04|\n",
      "|  Alabama|     No Activity|Oct-18-2003|  42|2003-04|\n",
      "|  Alabama|  Local Activity|Oct-25-2003|  43|2003-04|\n",
      "|  Alabama|        Sporadic|Nov-01-2003|  44|2003-04|\n",
      "+---------+----------------+-----------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['STATENAME', 'ACTIVITYESTIMATE', 'WEEKEND', 'WEEK', 'SEASON']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Flu.show(n=5) \n",
    "Flu.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "| STATENAME|   AREA|\n",
      "+----------+-------+\n",
      "|   Alabama| 135767|\n",
      "|    Alaska|1723337|\n",
      "|   Arizona| 295234|\n",
      "|  Arkansas| 137732|\n",
      "|California| 423967|\n",
      "+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['STATENAME', 'AREA']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Area.show(n=5) \n",
    "Area.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------+-------+\n",
      "|_c0| STATENAME|INCOME| SEASON|\n",
      "+---+----------+------+-------+\n",
      "|  2|   Alabama| 51113|2017-18|\n",
      "|  3|    Alaska| 72231|2017-18|\n",
      "|  4|   Arizona| 61125|2017-18|\n",
      "|  5|  Arkansas| 48829|2017-18|\n",
      "|  6|California| 69759|2017-18|\n",
      "+---+----------+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['_c0', 'STATENAME', 'INCOME', 'SEASON']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Income.show(n=5) \n",
    "Income.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------------+--------------+-----------------+\n",
      "| STATENAME|All persons|Under 65 years|Under 18 years|65 years and over|\n",
      "+----------+-----------+--------------+--------------+-----------------+\n",
      "|   Alabama|       84,6|          82,3|          91,1|             98,5|\n",
      "|    Alaska|       85,2|          82,9|          91,8|             99,8|\n",
      "|   Arizona|         81|          79,3|          83,5|             96,5|\n",
      "|  Arkansas|         82|          79,3|          86,3|             97,3|\n",
      "|California|       81,6|          78,6|          91,7|               98|\n",
      "+----------+-----------+--------------+--------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['STATENAME',\n",
       " 'All persons',\n",
       " 'Under 65 years',\n",
       " 'Under 18 years',\n",
       " '65 years and over']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Health.show(n=5) \n",
    "Health.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+---+-----+---+---+---+---+----+---+---+\n",
      "|_c0|WEEK| SEASON|AH3|AH1N1|  A|BVL|BYL|  B|H3N2| AU|AH1|\n",
      "+---+----+-------+---+-----+---+---+---+---+----+---+---+\n",
      "|  1|  40|2018-19| 11|   29|  8|  7| 11|  0|   0|  0|  0|\n",
      "|  2|  41|2018-19| 11|   49|  8|  3|  5|  5|   0|  0|  0|\n",
      "|  3|  42|2018-19| 18|   48| 13|  1| 12|  1|   0|  0|  0|\n",
      "|  4|  43|2018-19| 33|   73|  2|  0| 12|  2|   0|  0|  0|\n",
      "|  5|  44|2018-19| 20|   77|  3|  1|  8|  1|   0|  0|  0|\n",
      "+---+----+-------+---+-----+---+---+---+---+----+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'WEEK',\n",
       " 'SEASON',\n",
       " 'AH3',\n",
       " 'AH1N1',\n",
       " 'A',\n",
       " 'BVL',\n",
       " 'BYL',\n",
       " 'B',\n",
       " 'H3N2',\n",
       " 'AU',\n",
       " 'AH1']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Virus.show(n=5) \n",
    "Virus.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+\n",
      "| STATENAME|     POP| SEASON|\n",
      "+----------+--------+-------+\n",
      "|   Alabama| 4503491|2003-04|\n",
      "|    Alaska|  648414|2003-04|\n",
      "|   Arizona| 5510364|2003-04|\n",
      "|  Arkansas| 2724816|2003-04|\n",
      "|California|35253159|2003-04|\n",
      "+----------+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['STATENAME', 'POP', 'SEASON']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Population.show(n=5) \n",
    "Population.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+----------------+-----------+------------------+-------+\n",
      "|summary|STATENAME|ACTIVITYESTIMATE|    WEEKEND|              WEEK| SEASON|\n",
      "+-------+---------+----------------+-----------+------------------+-------+\n",
      "|  count|    29104|           29104|      29104|             29104|  29104|\n",
      "|   mean|     null|            null|       null|24.787073941726224|   null|\n",
      "| stddev|     null|            null|       null| 17.88996084805653|   null|\n",
      "|    min|  Alabama|  Local Activity|Apr-01-2006|                 1|2003-04|\n",
      "|    max|  Wyoming|      Widespread|Sep-26-2009|                 9|2018-19|\n",
      "+-------+---------+----------------+-----------+------------------+-------+\n",
      "\n",
      "+-------+---------+------------------+\n",
      "|summary|STATENAME|              AREA|\n",
      "+-------+---------+------------------+\n",
      "|  count|       57|                57|\n",
      "|   mean|     null|154560.36842105264|\n",
      "| stddev|     null|248208.14633716136|\n",
      "|    min|  Alabama|            104656|\n",
      "|    max|  Wyoming|              9998|\n",
      "+-------+---------+------------------+\n",
      "\n",
      "+-------+------------------+---------+------------------+-------+\n",
      "|summary|               _c0|STATENAME|            INCOME| SEASON|\n",
      "+-------+------------------+---------+------------------+-------+\n",
      "|  count|               816|      816|               816|    816|\n",
      "|   mean|             417.0|     null|51651.013480392154|   null|\n",
      "| stddev|240.30696116180673|     null| 9347.196205499946|   null|\n",
      "|    min|                10|  Alabama|             32002| 2003-4|\n",
      "|    max|                99|  Wyoming|             83382|2017-18|\n",
      "+-------+------------------+---------+------------------+-------+\n",
      "\n",
      "+-------+---------+-----------------+--------------+------------------+------------------+\n",
      "|summary|STATENAME|      All persons|Under 65 years|    Under 18 years| 65 years and over|\n",
      "+-------+---------+-----------------+--------------+------------------+------------------+\n",
      "|  count|       51|               52|            52|                52|                52|\n",
      "|   mean|     null|86.33333333333333|          82.0|              87.5| 98.66666666666667|\n",
      "| stddev|     null|4.412104562073146|           2.0|3.5355339059327378|0.5773502691896258|\n",
      "|    min|  Alabama|             75,4|          72,8|              81,7|              96,5|\n",
      "|    max|  Wyoming|             95,9|          95,2|              97,9|              99,9|\n",
      "+-------+---------+-----------------+--------------+------------------+------------------+\n",
      "\n",
      "+-------+-----------------+------------------+-------+------------------+------------------+------------------+-----------------+------------------+-----------------+-------------------+------------------+------------------+\n",
      "|summary|              _c0|              WEEK| SEASON|               AH3|             AH1N1|                 A|              BVL|               BYL|                B|               H3N2|                AU|               AH1|\n",
      "+-------+-----------------+------------------+-------+------------------+------------------+------------------+-----------------+------------------+-----------------+-------------------+------------------+------------------+\n",
      "|  count|              827|               827|    827|               827|               827|               827|              827|               827|              827|                827|               827|               827|\n",
      "|   mean|            414.0|26.533252720677147|   null|239.71825876662635|299.41519434628975|19.663845223700122|             29.5|             98.03|59.68923821039903|0.44014510278113667|0.9987908101571947|17.088270858524787|\n",
      "| stddev|238.8786302706879|15.161912087461774|   null| 540.0469862912779| 793.5078471034432|49.923119452799945|39.27073916765344|172.80014045918352|104.9855930057322|  4.695032043225055|7.5572871677025235| 74.44611093730327|\n",
      "|    min|                1|                 1| 2003-4|                 0|                 0|                 0|                0|                 0|                0|                  0|                 0|                 0|\n",
      "|    max|               99|                 9|2018-19|               997|                NA|                98|               NA|                NA|               98|                 94|                 9|                98|\n",
      "+-------+-----------------+------------------+-------+------------------+------------------+------------------+-----------------+------------------+-----------------+-------------------+------------------+------------------+\n",
      "\n",
      "+-------+---------+-----------------+-------+\n",
      "|summary|STATENAME|              POP| SEASON|\n",
      "+-------+---------+-----------------+-------+\n",
      "|  count|      816|              816|    816|\n",
      "|   mean|     null|6071396.414215687|   null|\n",
      "| stddev|     null|6819471.360813925|   null|\n",
      "|    min|  Alabama|         10001284|2003-04|\n",
      "|    max|  Wyoming|          9995915|2018-19|\n",
      "+-------+---------+-----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Flu.describe().show()\n",
    "Area.describe().show()\n",
    "Income.describe().show()\n",
    "Health.describe().show()\n",
    "Virus.describe().show()\n",
    "Population.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STATENAME: string (nullable = true)\n",
      " |-- ACTIVITYESTIMATE: string (nullable = true)\n",
      " |-- WEEKEND: string (nullable = true)\n",
      " |-- WEEK: string (nullable = true)\n",
      " |-- SEASON: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- STATENAME: string (nullable = true)\n",
      " |-- AREA: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- STATENAME: string (nullable = true)\n",
      " |-- INCOME: string (nullable = true)\n",
      " |-- SEASON: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- STATENAME: string (nullable = true)\n",
      " |-- All persons: string (nullable = true)\n",
      " |-- Under 65 years: string (nullable = true)\n",
      " |-- Under 18 years: string (nullable = true)\n",
      " |-- 65 years and over: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- WEEK: string (nullable = true)\n",
      " |-- SEASON: string (nullable = true)\n",
      " |-- AH3: string (nullable = true)\n",
      " |-- AH1N1: string (nullable = true)\n",
      " |-- A: string (nullable = true)\n",
      " |-- BVL: string (nullable = true)\n",
      " |-- BYL: string (nullable = true)\n",
      " |-- B: string (nullable = true)\n",
      " |-- H3N2: string (nullable = true)\n",
      " |-- AU: string (nullable = true)\n",
      " |-- AH1: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- STATENAME: string (nullable = true)\n",
      " |-- POP: string (nullable = true)\n",
      " |-- SEASON: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Flu.printSchema()\n",
    "Area.printSchema()\n",
    "Income.printSchema()\n",
    "Health.printSchema()\n",
    "Virus.printSchema()\n",
    "Population.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (StructField,StringType,IntegerType,StructType,FloatType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STATENAME: string (nullable = true)\n",
      " |-- ACTIVITYESTIMATE: string (nullable = true)\n",
      " |-- WEEKEND: string (nullable = true)\n",
      " |-- WEEK: integer (nullable = true)\n",
      " |-- SEASON: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_schema = [StructField('STATENAME',StringType(),True),\n",
    "              StructField('ACTIVITYESTIMATE',StringType(),True),\n",
    "              StructField('WEEKEND',StringType(),True),\n",
    "              StructField('WEEK',IntegerType(),True),\n",
    "              StructField('SEASON',StringType(),True)]\n",
    "\n",
    "final_struct = StructType(fields=data_schema)\n",
    "\n",
    "Flu = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \";\").schema(final_struct).load(\"Data/FluView.csv\") \n",
    "\n",
    "Flu.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STATENAME: string (nullable = true)\n",
      " |-- AREA: integer (nullable = true)\n",
      "\n",
      "+----------+-------+\n",
      "| STATENAME|   AREA|\n",
      "+----------+-------+\n",
      "|   Alabama| 135767|\n",
      "|    Alaska|1723337|\n",
      "|   Arizona| 295234|\n",
      "|  Arkansas| 137732|\n",
      "|California| 423967|\n",
      "+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_schema_Area = [StructField('STATENAME',StringType(),True),\n",
    "              StructField('AREA',IntegerType(),True)]\n",
    "\n",
    "final_struct_Area = StructType(fields=data_schema_Area)\n",
    "\n",
    "Area = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \"\\t\").schema(final_struct_Area).load(\"Data/Area.csv\") \n",
    "\n",
    "Area.printSchema()\n",
    "Area.show(n=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STATENAME: string (nullable = true)\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- INCOME: integer (nullable = true)\n",
      " |-- SEASON: string (nullable = true)\n",
      "\n",
      "+---------+----------+------+-------+\n",
      "|STATENAME|       _c0|INCOME| SEASON|\n",
      "+---------+----------+------+-------+\n",
      "|        2|   Alabama| 51113|2017-18|\n",
      "|        3|    Alaska| 72231|2017-18|\n",
      "|        4|   Arizona| 61125|2017-18|\n",
      "|        5|  Arkansas| 48829|2017-18|\n",
      "|        6|California| 69759|2017-18|\n",
      "+---------+----------+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_schema_income = [StructField('STATENAME',StringType(),True),\n",
    "              StructField('_c0',StringType(),True),\n",
    "              StructField('INCOME',IntegerType(),True),\n",
    "              StructField('SEASON',StringType(),True)]\n",
    "\n",
    "final_struct_income = StructType(fields=data_schema_income)\n",
    "\n",
    "Income = spark.read.format(\"csv\").option(\"header\", \"true\").schema(final_struct_income).load(\"Data/Income.csv\") \n",
    "\n",
    "Income.printSchema()\n",
    "Income.show(n=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STATENAME: string (nullable = true)\n",
      " |-- All persons: float (nullable = true)\n",
      " |-- Under 65 years: float (nullable = true)\n",
      " |-- Under 18 years: float (nullable = true)\n",
      " |-- 65 years and over: float (nullable = true)\n",
      "\n",
      "+----------+--------------+------------------+------------------+-----------------+\n",
      "| STATENAME|HealthCare_All|HealthCare_Under65|HealthCare_Under18|HealthCare_Over65|\n",
      "+----------+--------------+------------------+------------------+-----------------+\n",
      "|   Alabama|          84.6|              82.3|              91.1|             98.5|\n",
      "|    Alaska|          85.2|              82.9|              91.8|             99.8|\n",
      "|   Arizona|          81.0|              79.3|              83.5|             96.5|\n",
      "|  Arkansas|          82.0|              79.3|              86.3|             97.3|\n",
      "|California|          81.6|              78.6|              91.7|             98.0|\n",
      "+----------+--------------+------------------+------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Health = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \";\").load(\"Data/HealthCare.csv\")\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "Health = Health.withColumn('65 years and over',regexp_replace('65 years and over', ',', '.').cast('float'))\n",
    "Health = Health.withColumn('Under 65 years',regexp_replace('Under 65 years', ',', '.').cast('float'))\n",
    "Health = Health.withColumn('Under 18 years',regexp_replace('Under 18 years', ',', '.').cast('float'))\n",
    "Health = Health.withColumn('All persons',regexp_replace('All persons', ',', '.').cast('float'))\n",
    "\n",
    "Health.printSchema()\n",
    "\n",
    "Health = Health.withColumnRenamed('All persons', 'HealthCare_All')\n",
    "Health = Health.withColumnRenamed('Under 65 years', 'HealthCare_Under65')\n",
    "Health = Health.withColumnRenamed('Under 18 years', 'HealthCare_Under18')\n",
    "Health = Health.withColumnRenamed('65 years and over', 'HealthCare_Over65')\n",
    "\n",
    "Health.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- WEEK: integer (nullable = true)\n",
      " |-- SEASON: string (nullable = true)\n",
      " |-- AH3: integer (nullable = true)\n",
      " |-- AH1N1: integer (nullable = true)\n",
      " |-- A: integer (nullable = true)\n",
      " |-- BVL: integer (nullable = true)\n",
      " |-- BYL: integer (nullable = true)\n",
      " |-- B: integer (nullable = true)\n",
      " |-- H3N2: integer (nullable = true)\n",
      " |-- AU: integer (nullable = true)\n",
      " |-- AH1: integer (nullable = true)\n",
      "\n",
      "+---+----+-------+-----------+-------------+-----+-----------+-----------+-----+-------------+----------+-----------+\n",
      "|_c0|WEEK| SEASON|TypeA_subH3|TypeA_subH1N1|TypeA|TypeB_subVL|TypeB_subYL|TypeB|TypeA_subH3N2|TypeA_subU|TypeA_subH1|\n",
      "+---+----+-------+-----------+-------------+-----+-----------+-----------+-----+-------------+----------+-----------+\n",
      "|  1|  40|2018-19|         11|           29|    8|          7|         11|    0|            0|         0|          0|\n",
      "|  2|  41|2018-19|         11|           49|    8|          3|          5|    5|            0|         0|          0|\n",
      "|  3|  42|2018-19|         18|           48|   13|          1|         12|    1|            0|         0|          0|\n",
      "|  4|  43|2018-19|         33|           73|    2|          0|         12|    2|            0|         0|          0|\n",
      "|  5|  44|2018-19|         20|           77|    3|          1|          8|    1|            0|         0|          0|\n",
      "+---+----+-------+-----------+-------------+-----+-----------+-----------+-----+-------------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_schema_virus = [StructField('_c0',StringType(),True),\n",
    "              StructField('WEEK',IntegerType(),True),\n",
    "              StructField('SEASON',StringType(),True),\n",
    "              StructField('AH3',IntegerType(),True),\n",
    "              StructField('AH1N1',IntegerType(),True),\n",
    "              StructField('A',IntegerType(),True),\n",
    "              StructField('BVL',IntegerType(),True),\n",
    "              StructField('BYL',IntegerType(),True),\n",
    "              StructField('B',IntegerType(),True),\n",
    "              StructField('H3N2',IntegerType(),True),\n",
    "              StructField('AU',IntegerType(),True),\n",
    "              StructField('AH1',IntegerType(),True)]\n",
    "\n",
    "final_struct_virus = StructType(fields=data_schema_virus)\n",
    "Virus = spark.read.format(\"csv\").option(\"header\", \"true\").schema(final_struct_virus).load(\"Data/typeVirus.csv\")\n",
    "\n",
    "Virus.printSchema()\n",
    "\n",
    "Virus = Virus.withColumnRenamed('AH3', 'TypeA_subH3')\n",
    "Virus = Virus.withColumnRenamed('AH1N1', 'TypeA_subH1N1')\n",
    "Virus = Virus.withColumnRenamed('A', 'TypeA')\n",
    "Virus = Virus.withColumnRenamed('AU', 'TypeA_subU')\n",
    "Virus = Virus.withColumnRenamed('AH1', 'TypeA_subH1')\n",
    "Virus = Virus.withColumnRenamed('H3N2', 'TypeA_subH3N2')\n",
    "Virus = Virus.withColumnRenamed('B', 'TypeB')\n",
    "Virus = Virus.withColumnRenamed('BVL', 'TypeB_subVL')\n",
    "Virus = Virus.withColumnRenamed('BYL', 'TypeB_subYL')\n",
    "\n",
    "Virus.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STATENAME: string (nullable = true)\n",
      " |-- POP: integer (nullable = true)\n",
      " |-- SEASON: string (nullable = true)\n",
      "\n",
      "+----------+--------+-------+\n",
      "| STATENAME|     POP| SEASON|\n",
      "+----------+--------+-------+\n",
      "|   Alabama| 4503491|2003-04|\n",
      "|    Alaska|  648414|2003-04|\n",
      "|   Arizona| 5510364|2003-04|\n",
      "|  Arkansas| 2724816|2003-04|\n",
      "|California|35253159|2003-04|\n",
      "+----------+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_schema_pop = [StructField('STATENAME',StringType(),True),\n",
    "              StructField('POP',IntegerType(),True),\n",
    "              StructField('SEASON',StringType(),True)]\n",
    "\n",
    "final_struct_pop = StructType(fields=data_schema_pop)\n",
    "\n",
    "Population = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \"\\t\").schema(final_struct_pop).load(\"Data/population.csv\")\n",
    "\n",
    "Population.printSchema()\n",
    "Population.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
